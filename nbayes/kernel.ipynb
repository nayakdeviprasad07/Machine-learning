{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6c9c2b30-9954-3c05-5e70-7f4d0400df10",
    "_uuid": "0b366d5ac227bcae97793f2bff926ddde4168719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species  \\\n",
      "0            5.4           3.9            1.7           0.4        1   \n",
      "1            4.9           3.1            1.5           0.1        1   \n",
      "2            4.9           3.1            1.5           0.1        1   \n",
      "3            4.9           3.1            1.5           0.1        1   \n",
      "4            4.8           3.4            1.6           0.2        1   \n",
      "5            5.1           3.5            1.4           0.3        1   \n",
      "6            4.6           3.6            1.0           0.2        1   \n",
      "7            5.2           3.4            1.4           0.2        1   \n",
      "8            4.7           3.2            1.6           0.2        1   \n",
      "9            5.2           4.1            1.5           0.1        1   \n",
      "\n",
      "   Prediction  \n",
      "0         1.0  \n",
      "1         1.0  \n",
      "2         1.0  \n",
      "3         1.0  \n",
      "4         1.0  \n",
      "5         1.0  \n",
      "6         1.0  \n",
      "7         1.0  \n",
      "8         1.0  \n",
      "9         1.0  \n",
      "\n",
      "\n",
      "NB accuracy: 0.970000 (0.045826)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#load the csv file\n",
    "df=pd.read_csv('C:/Users/adhar/Documents/Courses/DataScience_Python/Sessions/Nbayes/input/Iris.csv')\n",
    "\n",
    "#Replace Species type with numbers\n",
    "df.Species.replace(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], [1, 2, 3], inplace=True)\n",
    "\n",
    "#Initialize Gaussian Naive Bayes\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Split-out validation dataset\n",
    "array = df.values\n",
    "X = array[:,1:5]\n",
    "Y = array[:,5]\n",
    "\n",
    "# One-third of data as a part of test set\n",
    "validation_size = 0.33\n",
    "\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "\n",
    "# Test options and evaluation metric\n",
    "scoring = 'accuracy'\n",
    "\n",
    "#Fitting the training set\n",
    "clf.fit(X_train, Y_train) \n",
    "\n",
    "#Predicting for the Test Set\n",
    "pred_clf = clf.predict(X_validation)\n",
    "\n",
    "#Prediction Probability\n",
    "prob_pos_clf = clf.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "#Create the prediction file by concatenation of the original data and predictions\n",
    "#Reshaping needed to perform the concatenation\n",
    "pred_clf_df = pd.DataFrame(pred_clf.reshape(50,1))\n",
    "#Column renaming to indicate the predictions\n",
    "pred_clf_df.rename(columns={0:'Prediction'}, inplace=True)\n",
    "\n",
    "#reshaping the test dataset\n",
    "X_validation_df = pd.DataFrame(X_validation.reshape(50,4))\n",
    "\n",
    "#concatenating the two pandas dataframes over the columns to create a prediction dataset\n",
    "pred_outcome = pd.concat([X_validation_df, pred_clf_df], axis=1, join_axes=[X_validation_df.index])\n",
    "\n",
    "pred_outcome.rename(columns = {0:'SepalLengthCm', 1:'SepalWidthCm', 2:'PetalLengthCm', 3:'PetalWidthCm'}, inplace=True)\n",
    "\n",
    "del df['Id']\n",
    "\n",
    "#merging the prediction with original dataset\n",
    "pred_comp = pd.merge(df,pred_outcome, on=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'])\n",
    "\n",
    "#print top 10 lines of the final predictions\n",
    "print((pred_comp).head(10))\n",
    "print (\"\\n\")\n",
    "\n",
    "#Save the file to csv\n",
    "pred_comp.to_csv('Predictions.csv', sep=',')\n",
    "\n",
    "#Save the file to Excel\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "writer = ExcelWriter('IrisPredictions.xlsx')\n",
    "pred_comp.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "\n",
    "\n",
    "#Model Performance\n",
    "#setting performance parameters\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "#calling the cross validation function\n",
    "cv_results = model_selection.cross_val_score(GaussianNB(), X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "#displaying the mean and standard deviation of the prediction\n",
    "msg = \"%s: %f (%f)\" % ('NB accuracy', cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
